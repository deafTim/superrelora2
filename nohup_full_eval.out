/home/jupyter/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at nicholasKluge/TeenyTinyLlama-160m and are newly initialized: ['model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/jupyter/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Loading model and tokenizer...
Checkpoint keys: ['model.model.embed_tokens.weight', 'model.model.layers.0.self_attn.q_proj.weight', 'model.model.layers.0.self_attn.q_proj.lora_A.weight', 'model.model.layers.0.self_attn.q_proj.lora_B.weight', 'model.model.layers.0.self_attn.k_proj.weight', 'model.model.layers.0.self_attn.k_proj.lora_A.weight', 'model.model.layers.0.self_attn.k_proj.lora_B.weight', 'model.model.layers.0.self_attn.v_proj.weight', 'model.model.layers.0.self_attn.v_proj.lora_A.weight', 'model.model.layers.0.self_attn.v_proj.lora_B.weight']
Model state_dict keys: ['model.model.embed_tokens.weight', 'model.model.layers.0.self_attn.q_proj.weight', 'model.model.layers.0.self_attn.q_proj.lora_A.weight', 'model.model.layers.0.self_attn.q_proj.lora_B.weight', 'model.model.layers.0.self_attn.k_proj.weight', 'model.model.layers.0.self_attn.k_proj.lora_A.weight', 'model.model.layers.0.self_attn.k_proj.lora_B.weight', 'model.model.layers.0.self_attn.v_proj.weight', 'model.model.layers.0.self_attn.v_proj.lora_A.weight', 'model.model.layers.0.self_attn.v_proj.lora_B.weight']
Loading dataset...
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 3698.53 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 3414.08 examples/s]
Computing metrics...

Starting evaluation on 125 batches...
Computing metrics:   0%|          | 0/125 [00:00<?, ?it/s]Computing metrics:   1%|          | 1/125 [00:02<04:44,  2.30s/it]Computing metrics:   2%|▏         | 2/125 [00:04<04:01,  1.97s/it]Computing metrics:   2%|▏         | 3/125 [00:05<03:46,  1.86s/it]Computing metrics:   3%|▎         | 4/125 [00:07<03:43,  1.84s/it]Computing metrics:   4%|▍         | 5/125 [00:09<03:34,  1.79s/it]Computing metrics:   5%|▍         | 6/125 [00:11<03:32,  1.79s/it]Computing metrics:   6%|▌         | 7/125 [00:12<03:31,  1.79s/it]Computing metrics:   6%|▋         | 8/125 [00:14<03:27,  1.77s/it]Computing metrics:   7%|▋         | 9/125 [00:16<03:25,  1.77s/it]Computing metrics:   8%|▊         | 10/125 [00:18<03:23,  1.77s/it]Computing metrics:   9%|▉         | 11/125 [00:19<03:16,  1.72s/it]Computing metrics:  10%|▉         | 12/125 [00:21<03:16,  1.74s/it]Computing metrics:  10%|█         | 13/125 [00:23<03:11,  1.71s/it]Computing metrics:  11%|█         | 14/125 [00:24<03:08,  1.70s/it]Computing metrics:  12%|█▏        | 15/125 [00:26<03:04,  1.68s/it]Computing metrics:  13%|█▎        | 16/125 [00:28<03:02,  1.68s/it]Computing metrics:  14%|█▎        | 17/125 [00:29<02:59,  1.67s/it]Computing metrics:  14%|█▍        | 18/125 [00:31<02:59,  1.68s/it]Computing metrics:  15%|█▌        | 19/125 [00:33<03:01,  1.71s/it]Computing metrics:  16%|█▌        | 20/125 [00:35<03:00,  1.72s/it]Computing metrics:  17%|█▋        | 21/125 [00:36<02:57,  1.71s/it]Computing metrics:  18%|█▊        | 22/125 [00:38<02:55,  1.71s/it]Computing metrics:  18%|█▊        | 23/125 [00:40<02:51,  1.68s/it]Computing metrics:  19%|█▉        | 24/125 [00:41<02:46,  1.65s/it]Computing metrics:  20%|██        | 25/125 [00:43<02:44,  1.64s/it]Computing metrics:  21%|██        | 26/125 [00:44<02:41,  1.63s/it]Computing metrics:  22%|██▏       | 27/125 [00:46<02:39,  1.63s/it]Computing metrics:  22%|██▏       | 28/125 [00:48<02:41,  1.66s/it]Computing metrics:  23%|██▎       | 29/125 [00:49<02:42,  1.69s/it]Computing metrics:  24%|██▍       | 30/125 [00:51<02:41,  1.70s/it]Computing metrics:  25%|██▍       | 31/125 [00:53<02:41,  1.72s/it]Computing metrics:  26%|██▌       | 32/125 [00:55<02:38,  1.70s/it]Computing metrics:  26%|██▋       | 33/125 [00:56<02:34,  1.68s/it]Computing metrics:  27%|██▋       | 34/125 [00:58<02:30,  1.65s/it]Computing metrics:  28%|██▊       | 35/125 [00:59<02:27,  1.64s/it]Computing metrics:  29%|██▉       | 36/125 [01:01<02:27,  1.66s/it]Computing metrics:  30%|██▉       | 37/125 [01:03<02:27,  1.68s/it]Computing metrics:  30%|███       | 38/125 [01:05<02:29,  1.72s/it]Computing metrics:  31%|███       | 39/125 [01:06<02:27,  1.71s/it]Computing metrics:  32%|███▏      | 40/125 [01:08<02:24,  1.70s/it]Computing metrics:  33%|███▎      | 41/125 [01:10<02:24,  1.72s/it]Computing metrics:  34%|███▎      | 42/125 [01:12<02:23,  1.73s/it]Computing metrics:  34%|███▍      | 43/125 [01:13<02:20,  1.72s/it]Computing metrics:  35%|███▌      | 44/125 [01:15<02:15,  1.68s/it]Computing metrics:  36%|███▌      | 45/125 [01:17<02:14,  1.68s/it]Computing metrics:  37%|███▋      | 46/125 [01:18<02:10,  1.65s/it]Computing metrics:  38%|███▊      | 47/125 [01:20<02:06,  1.62s/it]Computing metrics:  38%|███▊      | 48/125 [01:21<02:05,  1.63s/it]Computing metrics:  39%|███▉      | 49/125 [01:23<02:05,  1.64s/it]Computing metrics:  40%|████      | 50/125 [01:25<02:02,  1.63s/it]Computing metrics:  41%|████      | 51/125 [01:26<02:03,  1.67s/it]Computing metrics:  42%|████▏     | 52/125 [01:28<02:04,  1.70s/it]Computing metrics:  42%|████▏     | 53/125 [01:30<02:02,  1.70s/it]Computing metrics:  43%|████▎     | 54/125 [01:32<02:00,  1.70s/it]Computing metrics:  44%|████▍     | 55/125 [01:33<01:57,  1.68s/it]Computing metrics:  45%|████▍     | 56/125 [01:35<01:56,  1.69s/it]Computing metrics:  46%|████▌     | 57/125 [01:36<01:54,  1.68s/it]Computing metrics:  46%|████▋     | 58/125 [01:38<01:53,  1.70s/it]Computing metrics:  47%|████▋     | 59/125 [01:40<01:52,  1.71s/it]Computing metrics:  48%|████▊     | 60/125 [01:42<01:49,  1.68s/it]Computing metrics:  49%|████▉     | 61/125 [01:43<01:48,  1.69s/it]Computing metrics:  50%|████▉     | 62/125 [01:45<01:46,  1.69s/it]Computing metrics:  50%|█████     | 63/125 [01:47<01:44,  1.69s/it]Computing metrics:  51%|█████     | 64/125 [01:48<01:43,  1.70s/it]Computing metrics:  52%|█████▏    | 65/125 [01:50<01:42,  1.71s/it]Computing metrics:  53%|█████▎    | 66/125 [01:52<01:41,  1.73s/it]Computing metrics:  54%|█████▎    | 67/125 [01:54<01:40,  1.73s/it]Computing metrics:  54%|█████▍    | 68/125 [01:55<01:38,  1.73s/it]Computing metrics:  55%|█████▌    | 69/125 [01:57<01:35,  1.70s/it]Computing metrics:  56%|█████▌    | 70/125 [01:59<01:32,  1.68s/it]Computing metrics:  57%|█████▋    | 71/125 [02:00<01:29,  1.66s/it]Computing metrics:  58%|█████▊    | 72/125 [02:02<01:27,  1.66s/it]Computing metrics:  58%|█████▊    | 73/125 [02:04<01:26,  1.66s/it]Computing metrics:  59%|█████▉    | 74/125 [02:05<01:23,  1.64s/it]Computing metrics:  60%|██████    | 75/125 [02:07<01:22,  1.65s/it]Computing metrics:  61%|██████    | 76/125 [02:09<01:21,  1.67s/it]Computing metrics:  62%|██████▏   | 77/125 [02:10<01:21,  1.70s/it]Computing metrics:  62%|██████▏   | 78/125 [02:12<01:20,  1.71s/it]Computing metrics:  63%|██████▎   | 79/125 [02:14<01:18,  1.71s/it]Computing metrics:  64%|██████▍   | 80/125 [02:15<01:16,  1.70s/it]Computing metrics:  65%|██████▍   | 81/125 [02:17<01:14,  1.70s/it]Computing metrics:  66%|██████▌   | 82/125 [02:19<01:11,  1.67s/it]Computing metrics:  66%|██████▋   | 83/125 [02:20<01:09,  1.65s/it]Computing metrics:  67%|██████▋   | 84/125 [02:22<01:06,  1.62s/it]Computing metrics:  68%|██████▊   | 85/125 [02:24<01:05,  1.63s/it]Computing metrics:  69%|██████▉   | 86/125 [02:25<01:04,  1.67s/it]Computing metrics:  70%|██████▉   | 87/125 [02:27<01:03,  1.66s/it]Computing metrics:  70%|███████   | 88/125 [02:29<01:01,  1.65s/it]Computing metrics:  71%|███████   | 89/125 [02:30<00:59,  1.64s/it]Computing metrics:  72%|███████▏  | 90/125 [02:32<00:56,  1.63s/it]Computing metrics:  73%|███████▎  | 91/125 [02:34<00:56,  1.65s/it]Computing metrics:  74%|███████▎  | 92/125 [02:35<00:54,  1.65s/it]Computing metrics:  74%|███████▍  | 93/125 [02:37<00:52,  1.64s/it]Computing metrics:  75%|███████▌  | 94/125 [02:38<00:50,  1.63s/it]Computing metrics:  76%|███████▌  | 95/125 [02:40<00:49,  1.66s/it]Computing metrics:  77%|███████▋  | 96/125 [02:42<00:48,  1.69s/it]Computing metrics:  78%|███████▊  | 97/125 [02:44<00:47,  1.69s/it]Computing metrics:  78%|███████▊  | 98/125 [02:45<00:45,  1.68s/it]Computing metrics:  79%|███████▉  | 99/125 [02:47<00:43,  1.68s/it]Computing metrics:  80%|████████  | 100/125 [02:49<00:42,  1.72s/it]Computing metrics:  81%|████████  | 101/125 [02:50<00:40,  1.68s/it]Computing metrics:  82%|████████▏ | 102/125 [02:52<00:38,  1.68s/it]Computing metrics:  82%|████████▏ | 103/125 [02:54<00:36,  1.66s/it]Computing metrics:  83%|████████▎ | 104/125 [02:55<00:34,  1.63s/it]Computing metrics:  84%|████████▍ | 105/125 [02:57<00:33,  1.67s/it]Computing metrics:  85%|████████▍ | 106/125 [02:59<00:32,  1.69s/it]Computing metrics:  86%|████████▌ | 107/125 [03:00<00:29,  1.65s/it]Computing metrics:  86%|████████▋ | 108/125 [03:02<00:28,  1.69s/it]Computing metrics:  87%|████████▋ | 109/125 [03:04<00:27,  1.71s/it]Computing metrics:  88%|████████▊ | 110/125 [03:05<00:25,  1.72s/it]Computing metrics:  89%|████████▉ | 111/125 [03:07<00:23,  1.68s/it]Computing metrics:  90%|████████▉ | 112/125 [03:09<00:22,  1.69s/it]Computing metrics:  90%|█████████ | 113/125 [03:11<00:20,  1.72s/it]Computing metrics:  91%|█████████ | 114/125 [03:12<00:18,  1.72s/it]Computing metrics:  92%|█████████▏| 115/125 [03:14<00:16,  1.68s/it]Computing metrics:  93%|█████████▎| 116/125 [03:15<00:14,  1.66s/it]Computing metrics:  94%|█████████▎| 117/125 [03:17<00:13,  1.64s/it]Computing metrics:  94%|█████████▍| 118/125 [03:19<00:11,  1.68s/it]Computing metrics:  95%|█████████▌| 119/125 [03:21<00:10,  1.71s/it]Computing metrics:  96%|█████████▌| 120/125 [03:22<00:08,  1.71s/it]Computing metrics:  97%|█████████▋| 121/125 [03:24<00:06,  1.68s/it]Computing metrics:  98%|█████████▊| 122/125 [03:26<00:05,  1.70s/it]Computing metrics:  98%|█████████▊| 123/125 [03:27<00:03,  1.69s/it]Computing metrics:  99%|█████████▉| 124/125 [03:29<00:01,  1.72s/it]Computing metrics: 100%|██████████| 125/125 [03:31<00:00,  1.68s/it]Computing metrics: 100%|██████████| 125/125 [03:31<00:00,  1.69s/it]
Both `max_new_tokens` (=1024) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
2025-06-17 17:44:30.042178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Both `max_new_tokens` (=1024) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Both `max_new_tokens` (=1024) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

Processing batch 1/125
Batch shape: torch.Size([128, 8])
Batch 1 - Loss: 41.5688, Accuracy: 0.0179

Processing batch 2/125
Batch shape: torch.Size([128, 8])
Batch 2 - Loss: 26.0382, Accuracy: 0.0236

Processing batch 3/125
Batch shape: torch.Size([128, 8])
Batch 3 - Loss: 19.6405, Accuracy: 0.0134

Processing batch 4/125
Batch shape: torch.Size([128, 8])
Batch 4 - Loss: 30.1645, Accuracy: 0.0213

Processing batch 5/125
Batch shape: torch.Size([128, 8])
Batch 5 - Loss: 28.3091, Accuracy: 0.0160

Processing batch 6/125
Batch shape: torch.Size([128, 8])
Batch 6 - Loss: 29.3859, Accuracy: 0.0136

Processing batch 7/125
Batch shape: torch.Size([128, 8])
Batch 7 - Loss: 19.7347, Accuracy: 0.0171

Processing batch 8/125
Batch shape: torch.Size([128, 8])
Batch 8 - Loss: 33.7849, Accuracy: 0.0153

Processing batch 9/125
Batch shape: torch.Size([128, 8])
Batch 9 - Loss: 19.3601, Accuracy: 0.0168

Processing batch 10/125
Batch shape: torch.Size([128, 8])
Batch 10 - Loss: 45.7716, Accuracy: 0.0286

Processing batch 11/125
Batch shape: torch.Size([128, 8])
Batch 11 - Loss: 36.3344, Accuracy: 0.0180

Processing batch 12/125
Batch shape: torch.Size([128, 8])
Batch 12 - Loss: 35.0267, Accuracy: 0.0550

Processing batch 13/125
Batch shape: torch.Size([128, 8])
Batch 13 - Loss: 25.4656, Accuracy: 0.0258

Processing batch 14/125
Batch shape: torch.Size([128, 8])
Batch 14 - Loss: 21.3469, Accuracy: 0.0150

Processing batch 15/125
Batch shape: torch.Size([128, 8])
Batch 15 - Loss: 30.3991, Accuracy: 0.0150

Processing batch 16/125
Batch shape: torch.Size([128, 8])
Batch 16 - Loss: 28.9776, Accuracy: 0.0175

Processing batch 17/125
Batch shape: torch.Size([128, 8])
Batch 17 - Loss: 21.2544, Accuracy: 0.0208

Processing batch 18/125
Batch shape: torch.Size([128, 8])
Batch 18 - Loss: 19.3803, Accuracy: 0.0102

Processing batch 19/125
Batch shape: torch.Size([128, 8])
Batch 19 - Loss: 14.4835, Accuracy: 0.0156

Processing batch 20/125
Batch shape: torch.Size([128, 8])
Batch 20 - Loss: 19.1909, Accuracy: 0.0202

Processing batch 21/125
Batch shape: torch.Size([128, 8])
Batch 21 - Loss: 26.6669, Accuracy: 0.0167

Processing batch 22/125
Batch shape: torch.Size([128, 8])
Batch 22 - Loss: 18.5080, Accuracy: 0.0283

Processing batch 23/125
Batch shape: torch.Size([128, 8])
Batch 23 - Loss: 19.8432, Accuracy: 0.0105

Processing batch 24/125
Batch shape: torch.Size([128, 8])
Batch 24 - Loss: 19.6693, Accuracy: 0.0157

Processing batch 25/125
Batch shape: torch.Size([128, 8])
Batch 25 - Loss: 21.4191, Accuracy: 0.0151

Processing batch 26/125
Batch shape: torch.Size([128, 8])
Batch 26 - Loss: 20.4554, Accuracy: 0.0172

Processing batch 27/125
Batch shape: torch.Size([128, 8])
Batch 27 - Loss: 14.6419, Accuracy: 0.0156

Processing batch 28/125
Batch shape: torch.Size([128, 8])
Batch 28 - Loss: 41.3705, Accuracy: 0.0144

Processing batch 29/125
Batch shape: torch.Size([128, 8])
Batch 29 - Loss: 17.6534, Accuracy: 0.0169

Processing batch 30/125
Batch shape: torch.Size([128, 8])
Batch 30 - Loss: 19.3728, Accuracy: 0.0115

Processing batch 31/125
Batch shape: torch.Size([128, 8])
Batch 31 - Loss: 41.7330, Accuracy: 0.0180

Processing batch 32/125
Batch shape: torch.Size([128, 8])
Batch 32 - Loss: 51.2951, Accuracy: 0.0420

Processing batch 33/125
Batch shape: torch.Size([128, 8])
Batch 33 - Loss: 18.9466, Accuracy: 0.0312

Processing batch 34/125
Batch shape: torch.Size([128, 8])
Batch 34 - Loss: 37.3024, Accuracy: 0.0217

Processing batch 35/125
Batch shape: torch.Size([128, 8])
Batch 35 - Loss: 19.7296, Accuracy: 0.0192

Processing batch 36/125
Batch shape: torch.Size([128, 8])
Batch 36 - Loss: 51.8969, Accuracy: 0.0656

Processing batch 37/125
Batch shape: torch.Size([128, 8])
Batch 37 - Loss: 25.2897, Accuracy: 0.0496

Processing batch 38/125
Batch shape: torch.Size([128, 8])
Batch 38 - Loss: 20.8478, Accuracy: 0.0337

Processing batch 39/125
Batch shape: torch.Size([128, 8])
Batch 39 - Loss: 28.6822, Accuracy: 0.0309

Processing batch 40/125
Batch shape: torch.Size([128, 8])
Batch 40 - Loss: 25.4630, Accuracy: 0.0177

Processing batch 41/125
Batch shape: torch.Size([128, 8])
Batch 41 - Loss: 36.4185, Accuracy: 0.0251

Processing batch 42/125
Batch shape: torch.Size([128, 8])
Batch 42 - Loss: 22.8919, Accuracy: 0.0610

Processing batch 43/125
Batch shape: torch.Size([128, 8])
Batch 43 - Loss: 25.8426, Accuracy: 0.0256

Processing batch 44/125
Batch shape: torch.Size([128, 8])
Batch 44 - Loss: 27.3141, Accuracy: 0.0118

Processing batch 45/125
Batch shape: torch.Size([128, 8])
Batch 45 - Loss: 23.4423, Accuracy: 0.0175

Processing batch 46/125
Batch shape: torch.Size([128, 8])
Batch 46 - Loss: 23.0632, Accuracy: 0.0126

Processing batch 47/125
Batch shape: torch.Size([128, 8])
Batch 47 - Loss: 33.6584, Accuracy: 0.0138

Processing batch 48/125
Batch shape: torch.Size([128, 8])
Batch 48 - Loss: 41.5973, Accuracy: 0.0211

Processing batch 49/125
Batch shape: torch.Size([128, 8])
Batch 49 - Loss: 22.0859, Accuracy: 0.0294

Processing batch 50/125
Batch shape: torch.Size([128, 8])
Batch 50 - Loss: 51.1801, Accuracy: 0.0287

Processing batch 51/125
Batch shape: torch.Size([128, 8])
Batch 51 - Loss: 18.9049, Accuracy: 0.0133

Processing batch 52/125
Batch shape: torch.Size([128, 8])
Batch 52 - Loss: 27.2212, Accuracy: 0.0545

Processing batch 53/125
Batch shape: torch.Size([128, 8])
Batch 53 - Loss: 21.6203, Accuracy: 0.0417

Processing batch 54/125
Batch shape: torch.Size([128, 8])
Batch 54 - Loss: 42.7551, Accuracy: 0.0176

Processing batch 55/125
Batch shape: torch.Size([128, 8])
Batch 55 - Loss: 32.0217, Accuracy: 0.0194

Processing batch 56/125
Batch shape: torch.Size([128, 8])
Batch 56 - Loss: 20.3453, Accuracy: 0.0155

Processing batch 57/125
Batch shape: torch.Size([128, 8])
Batch 57 - Loss: 36.4266, Accuracy: 0.0179

Processing batch 58/125
Batch shape: torch.Size([128, 8])
Batch 58 - Loss: 21.2419, Accuracy: 0.0179

Processing batch 59/125
Batch shape: torch.Size([128, 8])
Batch 59 - Loss: 23.3669, Accuracy: 0.0227

Processing batch 60/125
Batch shape: torch.Size([128, 8])
Batch 60 - Loss: 19.4037, Accuracy: 0.0095

Processing batch 61/125
Batch shape: torch.Size([128, 8])
Batch 61 - Loss: 22.2050, Accuracy: 0.0323

Processing batch 62/125
Batch shape: torch.Size([128, 8])
Batch 62 - Loss: 52.5006, Accuracy: 0.0256

Processing batch 63/125
Batch shape: torch.Size([128, 8])
Batch 63 - Loss: 42.2189, Accuracy: 0.0387

Processing batch 64/125
Batch shape: torch.Size([128, 8])
Batch 64 - Loss: 43.5565, Accuracy: 0.0226

Processing batch 65/125
Batch shape: torch.Size([128, 8])
Batch 65 - Loss: 41.3468, Accuracy: 0.0174

Processing batch 66/125
Batch shape: torch.Size([128, 8])
Batch 66 - Loss: 41.3493, Accuracy: 0.0209

Processing batch 67/125
Batch shape: torch.Size([128, 8])
Batch 67 - Loss: 43.5947, Accuracy: 0.0153

Processing batch 68/125
Batch shape: torch.Size([128, 8])
Batch 68 - Loss: 41.0208, Accuracy: 0.0244

Processing batch 69/125
Batch shape: torch.Size([128, 8])
Batch 69 - Loss: 42.3182, Accuracy: 0.0201

Processing batch 70/125
Batch shape: torch.Size([128, 8])
Batch 70 - Loss: 52.6911, Accuracy: 0.0256

Processing batch 71/125
Batch shape: torch.Size([128, 8])
Batch 71 - Loss: 19.0943, Accuracy: 0.0152

Processing batch 72/125
Batch shape: torch.Size([128, 8])
Batch 72 - Loss: 42.1860, Accuracy: 0.0244

Processing batch 73/125
Batch shape: torch.Size([128, 8])
Batch 73 - Loss: 24.5289, Accuracy: 0.0145

Processing batch 74/125
Batch shape: torch.Size([128, 8])
Batch 74 - Loss: 20.0018, Accuracy: 0.0159

Processing batch 75/125
Batch shape: torch.Size([128, 8])
Batch 75 - Loss: 18.9804, Accuracy: 0.0210

Processing batch 76/125
Batch shape: torch.Size([128, 8])
Batch 76 - Loss: 27.6566, Accuracy: 0.0100

Processing batch 77/125
Batch shape: torch.Size([128, 8])
Batch 77 - Loss: 22.4752, Accuracy: 0.0201

Processing batch 78/125
Batch shape: torch.Size([128, 8])
Batch 78 - Loss: 35.2402, Accuracy: 0.0126

Processing batch 79/125
Batch shape: torch.Size([128, 8])
Batch 79 - Loss: 22.5027, Accuracy: 0.0177

Processing batch 80/125
Batch shape: torch.Size([128, 8])
Batch 80 - Loss: 22.1342, Accuracy: 0.0209

Processing batch 81/125
Batch shape: torch.Size([128, 8])
Batch 81 - Loss: 12.0780, Accuracy: 0.0814

Processing batch 82/125
Batch shape: torch.Size([128, 8])
Batch 82 - Loss: 12.6057, Accuracy: 0.1014

Processing batch 83/125
Batch shape: torch.Size([128, 8])
Batch 83 - Loss: 12.8370, Accuracy: 0.0800

Processing batch 84/125
Batch shape: torch.Size([128, 8])
Batch 84 - Loss: 27.9189, Accuracy: 0.0149

Processing batch 85/125
Batch shape: torch.Size([128, 8])
Batch 85 - Loss: 35.1089, Accuracy: 0.0276

Processing batch 86/125
Batch shape: torch.Size([128, 8])
Batch 86 - Loss: 23.3237, Accuracy: 0.0156

Processing batch 87/125
Batch shape: torch.Size([128, 8])
Batch 87 - Loss: 46.3844, Accuracy: 0.0338

Processing batch 88/125
Batch shape: torch.Size([128, 8])
Batch 88 - Loss: 19.1035, Accuracy: 0.0210

Processing batch 89/125
Batch shape: torch.Size([128, 8])
Batch 89 - Loss: 24.6567, Accuracy: 0.0255

Processing batch 90/125
Batch shape: torch.Size([128, 8])
Batch 90 - Loss: 18.9059, Accuracy: 0.0210

Processing batch 91/125
Batch shape: torch.Size([128, 8])
Batch 91 - Loss: 17.4743, Accuracy: 0.0168

Processing batch 92/125
Batch shape: torch.Size([128, 8])
Batch 92 - Loss: 18.4841, Accuracy: 0.0164

Processing batch 93/125
Batch shape: torch.Size([128, 8])
Batch 93 - Loss: 24.9838, Accuracy: 0.0158

Processing batch 94/125
Batch shape: torch.Size([128, 8])
Batch 94 - Loss: 26.2150, Accuracy: 0.0581

Processing batch 95/125
Batch shape: torch.Size([128, 8])
Batch 95 - Loss: 14.6920, Accuracy: 0.1000

Processing batch 96/125
Batch shape: torch.Size([128, 8])
Batch 96 - Loss: 19.3761, Accuracy: 0.0210

Processing batch 97/125
Batch shape: torch.Size([128, 8])
Batch 97 - Loss: 18.9046, Accuracy: 0.0210

Processing batch 98/125
Batch shape: torch.Size([128, 8])
Batch 98 - Loss: 21.0125, Accuracy: 0.0192

Processing batch 99/125
Batch shape: torch.Size([128, 8])
Batch 99 - Loss: 37.1342, Accuracy: 0.0185

Processing batch 100/125
Batch shape: torch.Size([128, 8])
Batch 100 - Loss: 22.5020, Accuracy: 0.0151

Processing batch 101/125
Batch shape: torch.Size([128, 8])
Batch 101 - Loss: 24.1852, Accuracy: 0.0160

Processing batch 102/125
Batch shape: torch.Size([128, 8])
Batch 102 - Loss: 24.0822, Accuracy: 0.0153

Processing batch 103/125
Batch shape: torch.Size([128, 8])
Batch 103 - Loss: 39.4914, Accuracy: 0.0195

Processing batch 104/125
Batch shape: torch.Size([128, 8])
Batch 104 - Loss: 38.8777, Accuracy: 0.0217

Processing batch 105/125
Batch shape: torch.Size([128, 8])
Batch 105 - Loss: 39.1399, Accuracy: 0.0110

Processing batch 106/125
Batch shape: torch.Size([128, 8])
Batch 106 - Loss: 25.6135, Accuracy: 0.0157

Processing batch 107/125
Batch shape: torch.Size([128, 8])
Batch 107 - Loss: 32.1203, Accuracy: 0.0178

Processing batch 108/125
Batch shape: torch.Size([128, 8])
Batch 108 - Loss: 19.1957, Accuracy: 0.0227

Processing batch 109/125
Batch shape: torch.Size([128, 8])
Batch 109 - Loss: 35.2789, Accuracy: 0.0101

Processing batch 110/125
Batch shape: torch.Size([128, 8])
Batch 110 - Loss: 28.1252, Accuracy: 0.0189

Processing batch 111/125
Batch shape: torch.Size([128, 8])
Batch 111 - Loss: 32.1574, Accuracy: 0.0204

Processing batch 112/125
Batch shape: torch.Size([128, 8])
Batch 112 - Loss: 31.7962, Accuracy: 0.0532

Processing batch 113/125
Batch shape: torch.Size([128, 8])
Batch 113 - Loss: 17.7638, Accuracy: 0.0169

Processing batch 114/125
Batch shape: torch.Size([128, 8])
Batch 114 - Loss: 13.8764, Accuracy: 0.1136

Processing batch 115/125
Batch shape: torch.Size([128, 8])
Batch 115 - Loss: 49.5530, Accuracy: 0.0246

Processing batch 116/125
Batch shape: torch.Size([128, 8])
Batch 116 - Loss: 13.6838, Accuracy: 0.0753

Processing batch 117/125
Batch shape: torch.Size([128, 8])
Batch 117 - Loss: 13.0753, Accuracy: 0.0842

Processing batch 118/125
Batch shape: torch.Size([128, 8])
Batch 118 - Loss: 12.2037, Accuracy: 0.1800

Processing batch 119/125
Batch shape: torch.Size([128, 8])
Batch 119 - Loss: 21.7984, Accuracy: 0.0205

Processing batch 120/125
Batch shape: torch.Size([128, 8])
Batch 120 - Loss: 37.1789, Accuracy: 0.0182

Processing batch 121/125
Batch shape: torch.Size([128, 8])
Batch 121 - Loss: 24.2488, Accuracy: 0.0133

Processing batch 122/125
Batch shape: torch.Size([128, 8])
Batch 122 - Loss: 20.4264, Accuracy: 0.0157

Processing batch 123/125
Batch shape: torch.Size([128, 8])
Batch 123 - Loss: 41.2319, Accuracy: 0.0266

Processing batch 124/125
Batch shape: torch.Size([128, 8])
Batch 124 - Loss: 23.5475, Accuracy: 0.0101

Processing batch 125/125
Batch shape: torch.Size([128, 8])
Batch 125 - Loss: 30.7057, Accuracy: 0.0101

Evaluation complete!
Total tokens processed: 43263
Total correct predictions: 852

SuperReLoRA Model Metrics:
Loss: 10.2898
Perplexity: 29430.45
Accuracy: 0.0197

Generating example texts:

Prompt: Once upon a time
Generated: Once upon a time , The Game Revolution also explores the game 's development of an evil manoeuvre throughout Britain . His previous appearances were both emotional and strongly drawn to their odes from himself in the same context ; however , only had " ... meaninglessness that was everyone ’ s getting more like ' I love You 'll get my son ! ' " It is shown that they could doubt the problems of some aspects of the game but noted that it had been much more difficult for players ( all the changes included ) , with not being imported by playerplayers , or as they would not accept the language of the game to react in their place . 
 The game has received critical response by critics , and after becoming the first video game to put out an average rather than two @-@ dimensional videos for a series of popular publishers , GameSpy describes it as " the most basically satisfactory video game dates " . In 2007 , IGN reviewed it as the best video game of all times . Reviews in mediaigned this title for its one @-@ page style theatrical version used , while reviewing the articles on Internet products were criticized for the attention of critics of the game . 
 
 The game has become popular among games such as Guitar Hero : Aerosmith & Playerunknown Band , Rock Band , and Band Hero . It is rated at number 18 on Rolling Stone magazine , namely at number 11 on GamesRadar and on Nintendo DS . 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Payback 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 


Prompt: The most important thing about
Generated: The most important thing about the poem was to develop it . It could mean what , so like that , to do so " they are seen more after a brightness himself — their own worn " , and " this idea is very different from " she 's known as fourth or early chorus . " 
 Before the state of writing – Fifth , and Tertiary in April 1885 , comment " I guess to the life , but even before we were so much greater time for fears , while and as of the night , by the mid @-@ twentieth century ... I know the life can say , " 
 In 1886 when Fifth took an essay on Poetry , Reines argued that the poem contains an example of this belief : 
 " I 'm not getting to think to things he doesn 't really everything if this word had its poetic action , " 
 " Every day before we 're out of his books , " 
 
 
 
 
 
 
 " Amore allies " 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 


Prompt: In the future, artificial intelligence will
Generated: In the future, artificial intelligence will be able to improve its production processing , learning that it is a strong problem ... It could have effective thinking about it 's anything elsewhere and they 're interacting with the humanity . " 
 
 
 
 
 Some knowledge of artificial intellectuality in the U.S. 
 Fine art : 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 representation for artificial intelligence , according to Richard Dawid 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 energia. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 World Fantasy Award 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

